{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from input_generator import load_dataset, load_dataset_with_lables\n",
    "from data_parser import get_tags_and_labels, get_vocab, get_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>tags0</th>\n",
       "      <th>tags1</th>\n",
       "      <th>tags2</th>\n",
       "      <th>tags3</th>\n",
       "      <th>tags4</th>\n",
       "      <th>tags5</th>\n",
       "      <th>tags6</th>\n",
       "      <th>tags7</th>\n",
       "      <th>tags8</th>\n",
       "      <th>tags9</th>\n",
       "      <th>tags10</th>\n",
       "      <th>tags11</th>\n",
       "      <th>tags12</th>\n",
       "      <th>tags13</th>\n",
       "      <th>tags14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>Walk</td>\n",
       "      <td>On</td>\n",
       "      <td>Water</td>\n",
       "      <td>Aftermath/Shady/Interscope</td>\n",
       "      <td>Rap</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>plush</td>\n",
       "      <td>bad unboxing</td>\n",
       "      <td>unboxing</td>\n",
       "      <td>fan mail</td>\n",
       "      <td>idubbbztv</td>\n",
       "      <td>idubbbztv2</td>\n",
       "      <td>things</td>\n",
       "      <td>best</td>\n",
       "      <td>packages</td>\n",
       "      <td>plushies</td>\n",
       "      <td>chontent chop</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>racist superman</td>\n",
       "      <td>rudy</td>\n",
       "      <td>mancuso</td>\n",
       "      <td>king</td>\n",
       "      <td>bach</td>\n",
       "      <td>racist</td>\n",
       "      <td>superman</td>\n",
       "      <td>love</td>\n",
       "      <td>rudy mancuso poo bear black white official mus...</td>\n",
       "      <td>iphone x by pineapple</td>\n",
       "      <td>lelepons</td>\n",
       "      <td>hannahstocking</td>\n",
       "      <td>rudymancuso</td>\n",
       "      <td>inanna</td>\n",
       "      <td>anwar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>ryan</td>\n",
       "      <td>higa</td>\n",
       "      <td>higatv</td>\n",
       "      <td>nigahiga</td>\n",
       "      <td>i dare you</td>\n",
       "      <td>idy</td>\n",
       "      <td>rhpc</td>\n",
       "      <td>dares</td>\n",
       "      <td>no truth</td>\n",
       "      <td>comments</td>\n",
       "      <td>comedy</td>\n",
       "      <td>funny</td>\n",
       "      <td>stupid</td>\n",
       "      <td>fail</td>\n",
       "      <td>notags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>edsheeran</td>\n",
       "      <td>ed sheeran</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>live</td>\n",
       "      <td>cover</td>\n",
       "      <td>official</td>\n",
       "      <td>remix</td>\n",
       "      <td>official video</td>\n",
       "      <td>lyrics</td>\n",
       "      <td>session</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id            tags0         tags1     tags2     tags3  \\\n",
       "0           10           Eminem          Walk        On     Water   \n",
       "1           23            plush  bad unboxing  unboxing  fan mail   \n",
       "2           23  racist superman          rudy   mancuso      king   \n",
       "3           24             ryan          higa    higatv  nigahiga   \n",
       "4           10        edsheeran    ed sheeran  acoustic      live   \n",
       "\n",
       "                        tags4       tags5     tags6           tags7  \\\n",
       "0  Aftermath/Shady/Interscope         Rap    notags          notags   \n",
       "1                   idubbbztv  idubbbztv2    things            best   \n",
       "2                        bach      racist  superman            love   \n",
       "3                  i dare you         idy      rhpc           dares   \n",
       "4                       cover    official     remix  official video   \n",
       "\n",
       "                                               tags8                  tags9  \\\n",
       "0                                             notags                 notags   \n",
       "1                                           packages               plushies   \n",
       "2  rudy mancuso poo bear black white official mus...  iphone x by pineapple   \n",
       "3                                           no truth               comments   \n",
       "4                                             lyrics                session   \n",
       "\n",
       "          tags10          tags11       tags12  tags13  tags14  \n",
       "0         notags          notags       notags  notags  notags  \n",
       "1  chontent chop          notags       notags  notags  notags  \n",
       "2       lelepons  hannahstocking  rudymancuso  inanna   anwar  \n",
       "3         comedy           funny       stupid    fail  notags  \n",
       "4         notags          notags       notags  notags  notags  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dataframe with tags and category_id columns\n",
    "csvpath = 'data/CAvideos.cvs'\n",
    "tab_dataframe = get_tags_and_labels(csvpath)\n",
    "\n",
    "# Creating different coloumn based on different tags\n",
    "new = tab_dataframe[\"tags\"].str.split(\".\", expand = True)\n",
    "\n",
    "max_of_tags = 15\n",
    "\n",
    "for i in range(0, max_of_tags):\n",
    "    name = \"tags\"+str(i)\n",
    "    tab_dataframe[name] = new[i]\n",
    "\n",
    "# Dropping old tags columns \n",
    "tab_dataframe.drop(columns =[\"tags\"], inplace = True) \n",
    "tab_dataframe.fillna(\"notags\", inplace = True) \n",
    "\n",
    "\n",
    "tab_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting leaning vocab\n",
    "vocab = get_vocab(get_tags(csvpath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0         97865.0\n",
       "1         56319.0\n",
       "2        102394.0\n",
       "3         86917.0\n",
       "4        125837.0\n",
       "           ...   \n",
       "40876      2914.0\n",
       "40877    103965.0\n",
       "40878     47551.0\n",
       "40879     37622.0\n",
       "40880     50086.0\n",
       "Name: tags0, Length: 40881, dtype: float64>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping tags to indexes in vocab\n",
    "for index in range(0, max_of_tags):\n",
    "    tab_dataframe['tags{}'.format(index)] = tab_dataframe['tags{}'.format(index)].map(voc_di)\n",
    "    \n",
    "tab_dataframe.fillna(0.0, inplace = True) \n",
    "tab_dataframe['tags0'].unique\n",
    "# tab_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>tags0</th>\n",
       "      <th>tags1</th>\n",
       "      <th>tags2</th>\n",
       "      <th>tags3</th>\n",
       "      <th>tags4</th>\n",
       "      <th>tags5</th>\n",
       "      <th>tags6</th>\n",
       "      <th>tags7</th>\n",
       "      <th>tags8</th>\n",
       "      <th>tags9</th>\n",
       "      <th>tags10</th>\n",
       "      <th>tags11</th>\n",
       "      <th>tags12</th>\n",
       "      <th>tags13</th>\n",
       "      <th>tags14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.593446</td>\n",
       "      <td>0.390095</td>\n",
       "      <td>0.038237</td>\n",
       "      <td>-1.354903</td>\n",
       "      <td>-1.029633</td>\n",
       "      <td>-1.102045</td>\n",
       "      <td>-0.351190</td>\n",
       "      <td>-1.285006</td>\n",
       "      <td>-1.210916</td>\n",
       "      <td>-1.190013</td>\n",
       "      <td>-1.122252</td>\n",
       "      <td>-1.084996</td>\n",
       "      <td>-1.037027</td>\n",
       "      <td>-0.994109</td>\n",
       "      <td>-0.950567</td>\n",
       "      <td>-0.917268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.325381</td>\n",
       "      <td>-0.548924</td>\n",
       "      <td>0.841871</td>\n",
       "      <td>1.442897</td>\n",
       "      <td>0.053094</td>\n",
       "      <td>-0.492575</td>\n",
       "      <td>-1.250101</td>\n",
       "      <td>1.786166</td>\n",
       "      <td>0.124584</td>\n",
       "      <td>1.251466</td>\n",
       "      <td>0.075815</td>\n",
       "      <td>0.767155</td>\n",
       "      <td>-1.037027</td>\n",
       "      <td>-0.994109</td>\n",
       "      <td>-0.950567</td>\n",
       "      <td>-0.917268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.325381</td>\n",
       "      <td>0.492459</td>\n",
       "      <td>1.658030</td>\n",
       "      <td>-0.380591</td>\n",
       "      <td>0.223491</td>\n",
       "      <td>-0.991603</td>\n",
       "      <td>1.438828</td>\n",
       "      <td>1.201242</td>\n",
       "      <td>1.680526</td>\n",
       "      <td>-0.402790</td>\n",
       "      <td>0.557300</td>\n",
       "      <td>1.620424</td>\n",
       "      <td>1.130516</td>\n",
       "      <td>-0.570936</td>\n",
       "      <td>1.839734</td>\n",
       "      <td>1.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.472983</td>\n",
       "      <td>0.142649</td>\n",
       "      <td>-0.813318</td>\n",
       "      <td>-0.842974</td>\n",
       "      <td>-0.501740</td>\n",
       "      <td>-0.761887</td>\n",
       "      <td>1.082209</td>\n",
       "      <td>0.986434</td>\n",
       "      <td>-0.060438</td>\n",
       "      <td>1.522101</td>\n",
       "      <td>0.877793</td>\n",
       "      <td>1.619337</td>\n",
       "      <td>1.820434</td>\n",
       "      <td>1.949531</td>\n",
       "      <td>0.730366</td>\n",
       "      <td>-0.917268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.593446</td>\n",
       "      <td>1.022316</td>\n",
       "      <td>-0.393781</td>\n",
       "      <td>-0.832569</td>\n",
       "      <td>0.312358</td>\n",
       "      <td>-1.216356</td>\n",
       "      <td>-1.019818</td>\n",
       "      <td>1.125975</td>\n",
       "      <td>-0.881581</td>\n",
       "      <td>0.506680</td>\n",
       "      <td>-0.646453</td>\n",
       "      <td>-1.084996</td>\n",
       "      <td>-1.037027</td>\n",
       "      <td>-0.994109</td>\n",
       "      <td>-0.950567</td>\n",
       "      <td>-0.917268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id     tags0     tags1     tags2     tags3     tags4     tags5  \\\n",
       "0    -1.593446  0.390095  0.038237 -1.354903 -1.029633 -1.102045 -0.351190   \n",
       "1     0.325381 -0.548924  0.841871  1.442897  0.053094 -0.492575 -1.250101   \n",
       "2     0.325381  0.492459  1.658030 -0.380591  0.223491 -0.991603  1.438828   \n",
       "3     0.472983  0.142649 -0.813318 -0.842974 -0.501740 -0.761887  1.082209   \n",
       "4    -1.593446  1.022316 -0.393781 -0.832569  0.312358 -1.216356 -1.019818   \n",
       "\n",
       "      tags6     tags7     tags8     tags9    tags10    tags11    tags12  \\\n",
       "0 -1.285006 -1.210916 -1.190013 -1.122252 -1.084996 -1.037027 -0.994109   \n",
       "1  1.786166  0.124584  1.251466  0.075815  0.767155 -1.037027 -0.994109   \n",
       "2  1.201242  1.680526 -0.402790  0.557300  1.620424  1.130516 -0.570936   \n",
       "3  0.986434 -0.060438  1.522101  0.877793  1.619337  1.820434  1.949531   \n",
       "4  1.125975 -0.881581  0.506680 -0.646453 -1.084996 -1.037027 -0.994109   \n",
       "\n",
       "     tags13    tags14  \n",
       "0 -0.950567 -0.917268  \n",
       "1 -0.950567 -0.917268  \n",
       "2  1.839734  1.050000  \n",
       "3  0.730366 -0.917268  \n",
       "4 -0.950567 -0.917268  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "df = tab_dataframe.copy()\n",
    "x = df.values\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "x_scaled = standard_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled, columns=tab_dataframe.columns)\n",
    "tab_dataframe = df\n",
    "\n",
    "tab_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train,validation and test examples from dataframe\n",
    "# train_ds, val_ds, test_ds = load_dataset(tab_dataframe)\n",
    "(train_ds, train_lb), (val_ds, val_lb), (test_ds, test_lb) = load_dataset_with_lables(tab_dataframe, 'category_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.54161807  1.06345585 -0.22506441  1.19241336 -0.74821889  0.39446741\n",
      "  -1.27098538  0.17042037  1.11995212  0.027279    0.13217428 -0.78737269\n",
      "   1.95444381 -0.95013596  1.66840667]\n",
      " [ 0.43545688 -0.67241037  1.02304572 -0.2936935  -1.03218823  0.16673761\n",
      "  -1.2538146   0.71085846  1.78026535  0.50725186  0.1797928   1.19478344\n",
      "   0.16460487 -0.44323089  0.15628976]\n",
      " [ 1.38900901  0.94692401  0.9996712   0.00834028  0.47105763 -0.37258884\n",
      "  -1.09905402  0.96803699 -0.51738928  1.60848941 -0.00412013 -1.03702658\n",
      "  -0.99410893 -0.95056728 -0.91726833]\n",
      " [ 0.07156608  0.30362021  0.62815839  1.73653919  1.69163792 -1.33442131\n",
      "  -1.28500649 -1.21091649 -1.19001319 -1.12225226 -1.084996   -1.03702658\n",
      "  -0.99410893 -0.95056728 -0.91726833]\n",
      " [ 0.25640453  1.17045129  1.47858387  1.74251203  1.09230364 -0.41520193\n",
      "  -0.59179454  1.57715978 -0.38891775 -0.01794972  1.05989001 -1.01967842\n",
      "  -0.14185032 -0.63640574 -0.44727041]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.59344644,  0.47298316,  0.47298316, -2.92186546, -0.1174253 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 training examples\n",
    "print(train_ds.values[5:10])\n",
    "train_lb.values[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0810 11:08:08.815292 10672 nn_ops.py:4220] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0810 11:08:08.899336 10672 nn_ops.py:4220] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0810 11:08:09.118706 10672 deprecation.py:323] From d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26163 samples, validate on 6541 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Received a label value of -2 which is outside the valid range of [0, 44).  Label values: 0 0 0 0 0 0 0 0 0 0 -2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 -1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 0 0\n\t [[node metrics/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-8-2af090a5e365>:19) ]] [Op:__inference_keras_scratch_graph_2287]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2af090a5e365>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                     validation_data=(val_ds, val_lb))\n\u001b[0m",
      "\u001b[1;32md:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32md:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32md:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3510\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3512\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m--> 572\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args)\u001b[0m\n\u001b[0;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[0;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[1;32m--> 445\u001b[1;33m             ctx=ctx)\n\u001b[0m\u001b[0;32m    446\u001b[0m       \u001b[1;31m# Replace empty list with None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\miniconda3\\envs\\deep\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  Received a label value of -2 which is outside the valid range of [0, 44).  Label values: 0 0 0 0 0 0 0 0 0 0 -2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 -1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 0 0\n\t [[node metrics/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-8-2af090a5e365>:19) ]] [Op:__inference_keras_scratch_graph_2287]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "hidden = 32\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Flatten(input_shape=(max_of_tags,)),\n",
    "    layers.Dense(hidden,activation='relu'),\n",
    "    layers.Dropout(0.7),\n",
    "    layers.Dense(2*hidden,activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.7),\n",
    "    layers.Dense(44, activation='softmax', kernel_regularizer=keras.regularizers.l2(0.01))])\n",
    "\n",
    "model.compile(optimizer='nadam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy', 'sparse_categorical_crossentropy'],\n",
    "              )\n",
    "\n",
    "history = model.fit(train_ds.values, train_lb.values,\n",
    "                    batch_size=64,\n",
    "                    epochs=100,\n",
    "                    validation_data=(val_ds, val_lb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
