{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from input_generator import load_dataset, load_dataset_with_lables\n",
    "from data_parser import get_tags_and_labels, get_vocab, get_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataframe with tags and category_id columns\n",
    "csvpath = 'data/CAvideos.cvs'\n",
    "tab_dataframe = get_tags_and_labels(csvpath)\n",
    "\n",
    "# Creating different coloumn based on different tags\n",
    "new = tab_dataframe[\"tags\"].str.split(\".\", expand = True)\n",
    "\n",
    "max_of_tags = 15\n",
    "\n",
    "for i in range(0, max_of_tags):\n",
    "    name = \"tags\"+str(i)\n",
    "    tab_dataframe[name] = new[i]\n",
    "\n",
    "# Dropping old tags columns \n",
    "tab_dataframe.drop(columns =[\"tags\"], inplace = True) \n",
    "tab_dataframe.fillna(\"notags\", inplace = True) \n",
    "\n",
    "\n",
    "tab_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting leaning vocab\n",
    "vocab = get_vocab(get_tags(csvpath))\n",
    "voc_di = {i:vo for i,vo in enumerate(vocab)}\n",
    "voc_di[0] = 'notags'\n",
    "voc_di = {vo:i for i, vo in voc_di.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mapping tags to indexes in vocab\n",
    "for index in range(0, max_of_tags):\n",
    "    tab_dataframe['tags{}'.format(index)] = tab_dataframe['tags{}'.format(index)].map(voc_di)\n",
    "    \n",
    "tab_dataframe.fillna(0.0, inplace = True) \n",
    "tab_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "df = tab_dataframe.copy()\n",
    "x = df.values\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "x_scaled = standard_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled, columns=tab_dataframe.columns)\n",
    "\n",
    "\n",
    "tab_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train,validation and test examples from dataframe\n",
    "# train_ds, val_ds, test_ds = load_dataset(tab_dataframe)\n",
    "(train_ds, train_lb), (val_ds, val_lb), (test_ds, test_lb) = load_dataset_with_lables(tab_dataframe, 'category_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 5 training examples\n",
    "print(train_ds.values[5:10])\n",
    "train_lb.values[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 32\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Flatten(input_shape=(max_of_words,)),\n",
    "    layers.Dense(hidden,activation='relu'),\n",
    "    layers.Dropout(0.7),\n",
    "    layers.Dense(2*hidden,activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.7),\n",
    "    layers.Dense(44, activation='softmax', kernel_regularizer=keras.regularizers.l2(0.01))])\n",
    "\n",
    "model.compile(optimizer='nadam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy', 'sparse_categorical_crossentropy'],\n",
    "              )\n",
    "\n",
    "history = model.fit(train_ds.values, train_lb.values,\n",
    "                    batch_size=64,\n",
    "                    epochs=100,\n",
    "                    validation_data=(val_ds, val_lb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
