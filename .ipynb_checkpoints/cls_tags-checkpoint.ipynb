{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ifDydRIDx7Pm"
   },
   "source": [
    "# Classyfing YouTube videos using tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACiOhi2mWh8V"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tag_handler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "colab_type": "code",
    "id": "eL9eaTrLx7Ps",
    "outputId": "40434405-9983-4f5e-a97b-06bfe6572b2f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from cvs_reader import *\n",
    "from vocab import *\n",
    "from dataframe_creator import create_seperate_columns, create_listed_columns\n",
    "\n",
    "# Get dataframes with tags and category_id as columns\n",
    "ca_csvpath = 'data/CAvideos.csv'\n",
    "us_csvpath = 'data/USvideos.csv'\n",
    "gb_csvpath = 'data/USvideos.csv'\n",
    "\n",
    "youtube_dfs = [load_dataframe(ca_csvpath, ['tags', 'category_id'])]\n",
    "youtube_dfs += [load_dataframe(us_csvpath, ['tags', 'category_id'])]\n",
    "youtube_dfs += [load_dataframe(gb_csvpath, ['tags', 'category_id'])]\n",
    "\n",
    "# Concat three dataframes into one\n",
    "tab_dataframe = pd.concat(youtube_dfs, ignore_index=True)\n",
    "tab_dataframe = tab_dataframe.dropna()\n",
    "tab_dataframe.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'none' values from dataframe\n",
    "junk = tab_dataframe[tab_dataframe['tags']=='[none]']\n",
    "tab_dataframe = pd.concat([tab_dataframe, junk, junk]).drop_duplicates(keep=False)\n",
    "tab_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5N5qOBsVjBs8"
   },
   "outputs": [],
   "source": [
    "# Spliting dataframe into several dfs based on category_id\n",
    "dfs = [x for _, x in tab_dataframe.groupby('category_id')]\n",
    "\n",
    "# deleting 3 categories (29, 30, 43) beacause of lack of frequency\n",
    "del dfs[14:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "resampled_dfs = []\n",
    "for df in dfs:\n",
    "    resampled_dfs += [resample(df, n_samples=4000)]\n",
    "\n",
    "# Resampling datas to make them balanced\n",
    "tab_dataframe = pd.concat(resampled_dfs, axis=0, ignore_index=True)\n",
    "tab_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R4l5v3CodBJF"
   },
   "outputs": [],
   "source": [
    "max_of_tags = 25\n",
    "\n",
    "vocab = get_tags_vocab(tab_dataframe['tags'])\n",
    "tab_dataframe = create_seperate_columns(tab_dataframe, max_of_tags, 'tags')\n",
    "tab_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "ZZnX4H9wx7Pv",
    "outputId": "abe50939-5c67-4885-d5d0-349902bfa4cb"
   },
   "outputs": [],
   "source": [
    "# Convert vocab to dictionary\n",
    "voc_di = get_tags_vocab_as_dict(vocab)\n",
    "\n",
    "# Mapping tags to indexes in vocab\n",
    "for col in tab_dataframe.columns:\n",
    "    if col == 'category_id':\n",
    "        continue\n",
    "    tab_dataframe[col] = tab_dataframe[col].map(voc_di)\n",
    "\n",
    "tab_dataframe.fillna(0, inplace = True) \n",
    "tab_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tvsJEkCkx7Pz"
   },
   "outputs": [],
   "source": [
    "future_df = []\n",
    "col_row_dict = {}\n",
    "# We only use 1/4 of the dataset!\n",
    "first_half_df = tab_dataframe[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mY94o9_ox7P1"
   },
   "outputs": [],
   "source": [
    "for i in range(0, 10000):\n",
    "    for col in first_half_df.columns:\n",
    "        if col == 'category_id':\n",
    "            col_row_dict.update({'category_id':first_half_df[col][i]})\n",
    "        else:\n",
    "            col_row_dict.update({'tag_{}'.format(first_half_df[col][i]):1.0})\n",
    "    future_df.append(col_row_dict)\n",
    "    col_row_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "eSL7MRm6x7P3",
    "outputId": "ff48cfe0-c6d1-4e52-8d85-84dd7bad88a6"
   },
   "outputs": [],
   "source": [
    "final_dataframe = pd.DataFrame(future_df)\n",
    "final_dataframe.fillna(0.0, inplace = True)\n",
    "from input_generator import load_dataset_with_lables\n",
    "final_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NkcAR0X9x7P5"
   },
   "outputs": [],
   "source": [
    "from input_generator import load_dataset_with_lables\n",
    "\n",
    "\n",
    "# Create train,validation and test examples from tags and labels dataframe\n",
    "(train_ds, train_lb), (val_ds, val_lb), (test_ds, test_lb) = load_dataset_with_lables(final_dataframe, 'category_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mTXEcDNOLV8f"
   },
   "outputs": [],
   "source": [
    "train_ds.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anu8_UhcLYHQ"
   },
   "outputs": [],
   "source": [
    "train_lb.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4deamqaKx7P8"
   },
   "outputs": [],
   "source": [
    "hidden = 128\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(hidden,activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(hidden,activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(2*hidden,activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(44, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              )\n",
    "\n",
    "history = model.fit(train_ds.values, train_lb.values,\n",
    "                    batch_size=32,\n",
    "                    epochs=6,\n",
    "                    validation_data=(val_ds.values, val_lb.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9i3WGhXCx7P-"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "plt.plot(acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ioAOt_5z8AqB"
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(test_ds, test_lb)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bQ300kmfNfr4"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_ds)\n",
    "cat_tit_dict = get_category_title_dict('/content/CA_category_id.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BN-KCiOtXLI6"
   },
   "outputs": [],
   "source": [
    "def one_hot_to_index(one_hot):\n",
    "    i_tags = []\n",
    "    for i, b in enumerate(one_hot):\n",
    "        if b == 1.0:\n",
    "        i_tags.append(i)      \n",
    "    return i_tags\n",
    "\n",
    "def index_to_tag(i_tags):\n",
    "w_tags = []\n",
    "reversed_vocab_dict = {i: vo for vo, i in voc_di.items()}\n",
    "for index in i_tags:\n",
    "    w_tags.append(reversed_vocab_dict[index])\n",
    "return w_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SezBZd2cO8ZT"
   },
   "outputs": [],
   "source": [
    "for i in range(30, 40):\n",
    "    one_hot = one_hot_to_index(test_ds.values[i])\n",
    "    tags_i = index_to_tag(one_hot)\n",
    "    print(tags_i)\n",
    "    print('predict:{}'.format(cat_tit_dict[str(np.argmax(predictions[i]))]))\n",
    "    print('true label:{}'.format(cat_tit_dict[str(test_lb.values[i])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "opbKCgUjWh88"
   },
   "source": [
    "# Classifying using tags, number of likes and number of comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2etheZExWh89"
   },
   "outputs": [],
   "source": [
    "full_dataframe = load_dataframe(csvpath, ['tags', 'likes', 'comment_count', 'category_id'])\n",
    "max_of_tags = 25\n",
    "\n",
    "full_dataframe = create_seperate_columns(full_dataframe, max_of_tags, 'tags')\n",
    "\n",
    "full_dataframe.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "cls_tags.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
