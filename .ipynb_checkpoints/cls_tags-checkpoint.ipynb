{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from input_generator import load_dataset, load_dataset_with_lables\n",
    "from data_parser import get_tags_and_labels, get_vocab, get_tags\n",
    "from df import create_seperate_columns, create_listed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>tags0</th>\n",
       "      <th>tags1</th>\n",
       "      <th>tags2</th>\n",
       "      <th>tags3</th>\n",
       "      <th>tags4</th>\n",
       "      <th>tags5</th>\n",
       "      <th>tags6</th>\n",
       "      <th>tags7</th>\n",
       "      <th>tags8</th>\n",
       "      <th>...</th>\n",
       "      <th>tags114</th>\n",
       "      <th>tags115</th>\n",
       "      <th>tags116</th>\n",
       "      <th>tags117</th>\n",
       "      <th>tags118</th>\n",
       "      <th>tags119</th>\n",
       "      <th>tags120</th>\n",
       "      <th>tags121</th>\n",
       "      <th>tags122</th>\n",
       "      <th>tags123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>Walk</td>\n",
       "      <td>On</td>\n",
       "      <td>Water</td>\n",
       "      <td>Aftermath/Shady/Interscope</td>\n",
       "      <td>Rap</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>...</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>plush</td>\n",
       "      <td>bad unboxing</td>\n",
       "      <td>unboxing</td>\n",
       "      <td>fan mail</td>\n",
       "      <td>idubbbztv</td>\n",
       "      <td>idubbbztv2</td>\n",
       "      <td>things</td>\n",
       "      <td>best</td>\n",
       "      <td>packages</td>\n",
       "      <td>...</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>racist superman</td>\n",
       "      <td>rudy</td>\n",
       "      <td>mancuso</td>\n",
       "      <td>king</td>\n",
       "      <td>bach</td>\n",
       "      <td>racist</td>\n",
       "      <td>superman</td>\n",
       "      <td>love</td>\n",
       "      <td>rudy mancuso poo bear black white official mus...</td>\n",
       "      <td>...</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>ryan</td>\n",
       "      <td>higa</td>\n",
       "      <td>higatv</td>\n",
       "      <td>nigahiga</td>\n",
       "      <td>i dare you</td>\n",
       "      <td>idy</td>\n",
       "      <td>rhpc</td>\n",
       "      <td>dares</td>\n",
       "      <td>no truth</td>\n",
       "      <td>...</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>edsheeran</td>\n",
       "      <td>ed sheeran</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>live</td>\n",
       "      <td>cover</td>\n",
       "      <td>official</td>\n",
       "      <td>remix</td>\n",
       "      <td>official video</td>\n",
       "      <td>lyrics</td>\n",
       "      <td>...</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "      <td>notags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id            tags0         tags1     tags2     tags3  \\\n",
       "0           10           Eminem          Walk        On     Water   \n",
       "1           23            plush  bad unboxing  unboxing  fan mail   \n",
       "2           23  racist superman          rudy   mancuso      king   \n",
       "3           24             ryan          higa    higatv  nigahiga   \n",
       "4           10        edsheeran    ed sheeran  acoustic      live   \n",
       "\n",
       "                        tags4       tags5     tags6           tags7  \\\n",
       "0  Aftermath/Shady/Interscope         Rap    notags          notags   \n",
       "1                   idubbbztv  idubbbztv2    things            best   \n",
       "2                        bach      racist  superman            love   \n",
       "3                  i dare you         idy      rhpc           dares   \n",
       "4                       cover    official     remix  official video   \n",
       "\n",
       "                                               tags8  ... tags114 tags115  \\\n",
       "0                                             notags  ...  notags  notags   \n",
       "1                                           packages  ...  notags  notags   \n",
       "2  rudy mancuso poo bear black white official mus...  ...  notags  notags   \n",
       "3                                           no truth  ...  notags  notags   \n",
       "4                                             lyrics  ...  notags  notags   \n",
       "\n",
       "  tags116 tags117 tags118 tags119 tags120 tags121 tags122 tags123  \n",
       "0  notags  notags  notags  notags  notags  notags  notags  notags  \n",
       "1  notags  notags  notags  notags  notags  notags  notags  notags  \n",
       "2  notags  notags  notags  notags  notags  notags  notags  notags  \n",
       "3  notags  notags  notags  notags  notags  notags  notags  notags  \n",
       "4  notags  notags  notags  notags  notags  notags  notags  notags  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dataframe with tags and category_id columns\n",
    "csvpath = 'data/CAvideos.cvs'\n",
    "tab_dataframe = get_tags_and_labels(csvpath)\n",
    "max_of_tags = 124\n",
    "tab_dataframe = create_seperate_columns(tab_dataframe, max_of_tags, 'tags')\n",
    "\n",
    "tab_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>tags0</th>\n",
       "      <th>tags1</th>\n",
       "      <th>tags2</th>\n",
       "      <th>tags3</th>\n",
       "      <th>tags4</th>\n",
       "      <th>tags5</th>\n",
       "      <th>tags6</th>\n",
       "      <th>tags7</th>\n",
       "      <th>tags8</th>\n",
       "      <th>...</th>\n",
       "      <th>tags114</th>\n",
       "      <th>tags115</th>\n",
       "      <th>tags116</th>\n",
       "      <th>tags117</th>\n",
       "      <th>tags118</th>\n",
       "      <th>tags119</th>\n",
       "      <th>tags120</th>\n",
       "      <th>tags121</th>\n",
       "      <th>tags122</th>\n",
       "      <th>tags123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>48651.0</td>\n",
       "      <td>69386.0</td>\n",
       "      <td>125693.0</td>\n",
       "      <td>43961.0</td>\n",
       "      <td>150513.0</td>\n",
       "      <td>17913.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>110656.0</td>\n",
       "      <td>62582.0</td>\n",
       "      <td>84342.0</td>\n",
       "      <td>92071.0</td>\n",
       "      <td>31082.0</td>\n",
       "      <td>92300.0</td>\n",
       "      <td>39276.0</td>\n",
       "      <td>33467.0</td>\n",
       "      <td>66914.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>132355.0</td>\n",
       "      <td>147778.0</td>\n",
       "      <td>65657.0</td>\n",
       "      <td>111369.0</td>\n",
       "      <td>63363.0</td>\n",
       "      <td>22664.0</td>\n",
       "      <td>118042.0</td>\n",
       "      <td>11366.0</td>\n",
       "      <td>28212.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>59504.0</td>\n",
       "      <td>36159.0</td>\n",
       "      <td>66304.0</td>\n",
       "      <td>51924.0</td>\n",
       "      <td>88956.0</td>\n",
       "      <td>34592.0</td>\n",
       "      <td>112652.0</td>\n",
       "      <td>52889.0</td>\n",
       "      <td>63109.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>60900.0</td>\n",
       "      <td>119011.0</td>\n",
       "      <td>139350.0</td>\n",
       "      <td>44088.0</td>\n",
       "      <td>28750.0</td>\n",
       "      <td>18883.0</td>\n",
       "      <td>131606.0</td>\n",
       "      <td>29316.0</td>\n",
       "      <td>126217.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id     tags0     tags1     tags2     tags3     tags4    tags5  \\\n",
       "0           10   48651.0   69386.0  125693.0   43961.0  150513.0  17913.0   \n",
       "1           23  110656.0   62582.0   84342.0   92071.0   31082.0  92300.0   \n",
       "2           23  132355.0  147778.0   65657.0  111369.0   63363.0  22664.0   \n",
       "3           24   59504.0   36159.0   66304.0   51924.0   88956.0  34592.0   \n",
       "4           10   60900.0  119011.0  139350.0   44088.0   28750.0  18883.0   \n",
       "\n",
       "      tags6    tags7     tags8  ...  tags114  tags115  tags116  tags117  \\\n",
       "0       0.0      0.0       0.0  ...        0        0        0        0   \n",
       "1   39276.0  33467.0   66914.0  ...        0        0        0        0   \n",
       "2  118042.0  11366.0   28212.0  ...        0        0        0        0   \n",
       "3  112652.0  52889.0   63109.0  ...        0        0        0        0   \n",
       "4  131606.0  29316.0  126217.0  ...        0        0        0        0   \n",
       "\n",
       "   tags118  tags119  tags120  tags121  tags122  tags123  \n",
       "0        0        0        0        0        0        0  \n",
       "1        0        0        0        0        0        0  \n",
       "2        0        0        0        0        0        0  \n",
       "3        0        0        0        0        0        0  \n",
       "4        0        0        0        0        0        0  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting leaning vocab\n",
    "vocab = get_vocab(get_tags(csvpath))\n",
    "\n",
    "# Turn vocab to dictionary\n",
    "voc_di = {i: vo for i, vo in enumerate(vocab)}\n",
    "voc_di[0] = 'notags'\n",
    "voc_di = {vo: i for i, vo in voc_di.items()}\n",
    "\n",
    "# Mapping tags to indexes in vocab\n",
    "for index in range(0, max_of_tags):\n",
    "    tab_dataframe['tags{}'.format(index)] = tab_dataframe['tags{}'.format(index)].map(voc_di)\n",
    "\n",
    "tab_dataframe.fillna(0.0, inplace = True) \n",
    "tab_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_df = []\n",
    "col_row_dict = {}\n",
    "\n",
    "for i in range(0, max_of_tags):\n",
    "    for col in tab_dataframe.columns:\n",
    "        if col == 'category_id':\n",
    "            col_row_dict.update({'category_id':tab_dataframe[col][i]})\n",
    "        else:\n",
    "            col_row_dict.update({'tag{}'.format(tab_dataframe[col][i]):1.0})\n",
    "    future_df.append(col_row_dict)\n",
    "    col_row_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_fd = pd.DataFrame(future_df)\n",
    "voc_fd.fillna(0.0, inplace = True)\n",
    "voc_fd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train,validation and test examples from dataframe\n",
    "# train_ds, val_ds, test_ds = load_dataset(tab_dataframe)\n",
    "(train_ds, train_lb), (val_ds, val_lb), (test_ds, test_lb) = load_dataset_with_lables(voc_fd, 'category_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([22, 24, 24, 28,  1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 training examples\n",
    "print(train_ds.values[5:10])\n",
    "train_lb.values[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79 samples, validate on 20 samples\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 0s 6ms/sample - loss: 3.9630 - accuracy: 0.0380 - val_loss: 3.9131 - val_accuracy: 0.2000\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 203us/sample - loss: 3.8650 - accuracy: 0.3291 - val_loss: 3.8757 - val_accuracy: 0.3000\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 317us/sample - loss: 3.7659 - accuracy: 0.5570 - val_loss: 3.8335 - val_accuracy: 0.2500\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 367us/sample - loss: 3.6461 - accuracy: 0.6329 - val_loss: 3.7825 - val_accuracy: 0.2000\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 443us/sample - loss: 3.4913 - accuracy: 0.6076 - val_loss: 3.7186 - val_accuracy: 0.2500\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 418us/sample - loss: 3.2902 - accuracy: 0.5570 - val_loss: 3.6338 - val_accuracy: 0.2000\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 633us/sample - loss: 3.0322 - accuracy: 0.4937 - val_loss: 3.5282 - val_accuracy: 0.2000\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 494us/sample - loss: 2.7216 - accuracy: 0.4810 - val_loss: 3.4010 - val_accuracy: 0.1500\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 583us/sample - loss: 2.4065 - accuracy: 0.4177 - val_loss: 3.2683 - val_accuracy: 0.2000\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 418us/sample - loss: 2.1187 - accuracy: 0.4810 - val_loss: 3.1429 - val_accuracy: 0.2000\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 393us/sample - loss: 1.8747 - accuracy: 0.5190 - val_loss: 3.0236 - val_accuracy: 0.2500\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 595us/sample - loss: 1.6564 - accuracy: 0.6329 - val_loss: 2.9236 - val_accuracy: 0.2500\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 412us/sample - loss: 1.4657 - accuracy: 0.7215 - val_loss: 2.8447 - val_accuracy: 0.2000\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 380us/sample - loss: 1.2877 - accuracy: 0.8354 - val_loss: 2.7776 - val_accuracy: 0.2000\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 405us/sample - loss: 1.1389 - accuracy: 0.8608 - val_loss: 2.7384 - val_accuracy: 0.1500\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 329us/sample - loss: 1.0051 - accuracy: 0.8861 - val_loss: 2.7011 - val_accuracy: 0.1500\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 329us/sample - loss: 0.8945 - accuracy: 0.8987 - val_loss: 2.6771 - val_accuracy: 0.1500\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 291us/sample - loss: 0.8012 - accuracy: 0.8987 - val_loss: 2.6659 - val_accuracy: 0.1500\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 241us/sample - loss: 0.7206 - accuracy: 0.9241 - val_loss: 2.6680 - val_accuracy: 0.1500\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 291us/sample - loss: 0.6526 - accuracy: 0.9494 - val_loss: 2.6543 - val_accuracy: 0.1500\n"
     ]
    }
   ],
   "source": [
    "hidden = 64\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(hidden,activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    layers.Dense(2*hidden,activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    layers.Dense(44, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer='nadam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              )\n",
    "\n",
    "history = model.fit(train_ds.values, train_lb.values,\n",
    "                    batch_size=32,\n",
    "                    epochs=20,\n",
    "                    validation_data=(val_ds, val_lb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
